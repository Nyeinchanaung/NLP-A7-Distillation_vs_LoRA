{"cells":[{"cell_type":"markdown","metadata":{"id":"LmdLpW7KjyOJ"},"source":["# A7: Training Distillation vs LoRA"]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJOhI808kDQQ","executionInfo":{"status":"ok","timestamp":1742460079401,"user_tz":-420,"elapsed":7060,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"afdb4ed0-e27d-48c4-d47e-7881ddadadd7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.4.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXlU4KYwjyOL","executionInfo":{"status":"ok","timestamp":1742460090565,"user_tz":-420,"elapsed":11161,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"f0270b26-dae7-4bc2-f37b-17900bac7ec7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('3.4.1', '4.48.3', '2.6.0+cu124')"]},"metadata":{},"execution_count":3}],"source":["# !pip install datasets --upgrade\n","import datasets\n","import transformers\n","import torch\n","datasets.__version__, transformers.__version__, torch.__version__"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6Ll_YwfjyOM","executionInfo":{"status":"ok","timestamp":1742460090763,"user_tz":-420,"elapsed":34,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"3a37a670-ff21-409f-fd93-371fe82e6b5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch.nn as nn\n","import torch\n","from tqdm.auto import tqdm\n","import random, math, time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","#make our work comparable if restarted the kernel\n","SEED = 1234\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"Rg5qh3jxjyOM"},"source":["# 1. Load HateXplain Dataset from Hugging Face"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"aYw3G0ZAjyOM","executionInfo":{"status":"error","timestamp":1742460069008,"user_tz":-420,"elapsed":92,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"f3b9ddb9-3e58-4d86-9fb5-fbc706ed6d78"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'datasets'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fd702ef9724a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the HateXplain dataset from Hugging Face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hate_speech_offensive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from datasets import load_dataset\n","\n","# Load the HateXplain dataset from Hugging Face\n","dataset = load_dataset(\"hate_speech_offensive\")\n","\n","# # Check dataset structure\n","print(dataset)"]},{"cell_type":"code","source":["# count lable dataset\n"],"metadata":{"id":"zQwxqUhSkbwA","executionInfo":{"status":"ok","timestamp":1742459277956,"user_tz":-420,"elapsed":103,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pV4cU-eYjyOM","executionInfo":{"status":"ok","timestamp":1742459277956,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Label Mapping\n","label_list = [\"Non-Hate\", \"Offensive\", \"Hate\"]\n","label2id = {v: i for i, v in enumerate(label_list)}\n","id2label = {i: v for v, i in label2id.items()}"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"XtCW7KYzjyON","executionInfo":{"status":"ok","timestamp":1742459277957,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Assign feature key\n","task_to_keys = {\"hatexplain\": \"tweet\"}\n","task_name = \"hatexplain\"\n","sentence_key = task_to_keys[task_name]"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23d-VwA9jyON","executionInfo":{"status":"ok","timestamp":1742459277977,"user_tz":-420,"elapsed":23,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"af97cd30-68ab-40a3-fcfd-c33c82b38ada"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'class', 'tweet'],\n","        num_rows: 24783\n","    })\n","})\n","Example: !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\n","Label2ID: {'Non-Hate': 0, 'Offensive': 1, 'Hate': 2}\n","ID2Label: {0: 'Non-Hate', 1: 'Offensive', 2: 'Hate'}\n"]}],"source":["# Print dataset overview\n","print(dataset)\n","print(\"Example:\", dataset[\"train\"][0][sentence_key])\n","print(\"Label2ID:\", label2id)\n","print(\"ID2Label:\", id2label)"]},{"cell_type":"markdown","metadata":{"id":"ODDlx40QjyON"},"source":["# 2. Tokenization and Data Preprocessing"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MowCG2IMjyON","executionInfo":{"status":"ok","timestamp":1742459277982,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"266a8aaa-041e-4771-96d0-1b77d4c16a5e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":24}],"source":["# Check number of unique labels\n","num_labels = len(label_list)\n","num_labels"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"jYJFGlTRjyON","executionInfo":{"status":"ok","timestamp":1742459277986,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["import numpy as np\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","# Load BERT tokenizer\n","teacher_id = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(teacher_id)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suFsg59ajyON","executionInfo":{"status":"ok","timestamp":1742459278090,"user_tz":-420,"elapsed":103,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"6bbe2406-c0d5-4f3a-9bcb-1e6d982519ea"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load Teacher Model (BERT)\n","teacher_model = AutoModelForSequenceClassification.from_pretrained(\n","    teacher_id,\n","    num_labels=num_labels,\n","    id2label=id2label,\n","    label2id=label2id,\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"6cItHUN2jyON","executionInfo":{"status":"ok","timestamp":1742459278115,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Tokenization Function (Modified for HateXplain)\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"tweet\"], max_length=128, truncation=True, padding=\"max_length\")"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEtHitVYjyON","executionInfo":{"status":"ok","timestamp":1742459278147,"user_tz":-420,"elapsed":31,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"92b0e7a3-97f6-44f8-bcc1-498dc5c95530"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([  101,   999,   999,   999, 19387,  1030,  9815, 19454, 21818,  2135,\n","         1024,  2004,  1037,  2450,  2017,  5807,  1005,  1056, 17612,  2055,\n","         9344,  2039,  2115,  2160,  1012,  1004, 23713,  1025,  2004,  1037,\n","         2158,  2017,  2323,  2467,  2202,  1996, 11669,  2041,  1012,  1012,\n","         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","[CLS]!!! rt @ mayasolovely : as a woman you shouldn ' t complain about cleaning up your house. & amp ; as a man you should always take the trash out... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}],"source":["# Apply Tokenization\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","\n","# Remove unnecessary columns\n","tokenized_datasets = tokenized_datasets.remove_columns([\"count\", \"hate_speech_count\", \"offensive_language_count\", \"neither_count\", \"tweet\"])\n","\n","# Rename \"class\" column to \"labels\" for PyTorch compatibility\n","tokenized_datasets = tokenized_datasets.rename_column(\"class\", \"labels\")\n","\n","# Set dataset format for PyTorch\n","tokenized_datasets.set_format(\"torch\")\n","\n","# Print an example tokenized input\n","print(tokenized_datasets[\"train\"][0][\"input_ids\"])\n","print(tokenizer.decode(tokenized_datasets[\"train\"][0][\"input_ids\"]))"]},{"cell_type":"markdown","metadata":{"id":"oWxahqDTjyOO"},"source":["# 3. Preparing Dataloader"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"iob1eV6tjyOO","executionInfo":{"status":"ok","timestamp":1742459278247,"user_tz":-420,"elapsed":99,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","from torch.utils.data import DataLoader\n","\n","# Data Collator (Handles Dynamic Padding)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"WfWFLbuujyOO","executionInfo":{"status":"ok","timestamp":1742459278248,"user_tz":-420,"elapsed":72,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Subset dataset for efficiency\n","small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(10000))  # 10K samples\n","small_eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(1000))    # 1K samples (same train split)\n","small_test_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(1000))    # 1K samples (same train split)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"HtFyg4oyjyOO","executionInfo":{"status":"ok","timestamp":1742459278248,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Create Dataloaders\n","train_dataloader = DataLoader(\n","    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator\n",")\n","test_dataloader = DataLoader(\n","    small_test_dataset, batch_size=32, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    small_eval_dataset, batch_size=32, collate_fn=data_collator\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8iqzKaHmjyOO","executionInfo":{"status":"ok","timestamp":1742459278255,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"e8e47bcd-02f4-4098-d254-161bfc330b94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32]), torch.Size([32, 128]), torch.Size([32, 128]))"]},"metadata":{},"execution_count":32}],"source":["# Check first batch\n","for batch in train_dataloader:\n","    break\n","\n","batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"]},{"cell_type":"markdown","metadata":{"id":"N1KtsA-BjyOO"},"source":["# 4. Model Training for Even and Odd Layers"]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGf3BdkPqqwK","executionInfo":{"status":"ok","timestamp":1742459297422,"user_tz":-420,"elapsed":3727,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"3fc7d588-2f75-4dcc-e94e-f989ed80b0a3"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n"]}]},{"cell_type":"code","execution_count":35,"metadata":{"id":"N5MJpKfpjyOO","executionInfo":{"status":"ok","timestamp":1742459298596,"user_tz":-420,"elapsed":267,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel, BertConfig\n","from tqdm.auto import tqdm\n","import evaluate\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get teacher configuration as a dictionary\n","configuration = teacher_model.config.to_dict()"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"uNGjn9DFjyOO","executionInfo":{"status":"ok","timestamp":1742459303119,"user_tz":-420,"elapsed":22,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Half the number of hidden layers (6 instead of 12)\n","configuration[\"num_hidden_layers\"] = 6\n","\n","# Convert dictionary to student configuration\n","configuration = BertConfig.from_dict(configuration)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"kVlA-57LjyOO","executionInfo":{"status":"ok","timestamp":1742459306140,"user_tz":-420,"elapsed":3020,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Create uninitialized student models for Odd & Even Layer Training\n","student_model_odd = type(teacher_model)(configuration)\n","student_model_even = type(teacher_model)(configuration)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8r871rPjyOO","executionInfo":{"status":"ok","timestamp":1742459306173,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"6e47a25e-f67a-4b78-c12c-a1ccdb97aff2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-5): 6 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":38}],"source":["student_model_even"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"yNgBZ7MljyOO","executionInfo":{"status":"ok","timestamp":1742459306173,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["def distill_bert_weights(teacher, student, layer_type=\"odd\"):\n","    \"\"\"\n","    Copies weights from the teacher model to the student model.\n","    Only copies odd or even layers as specified by `layer_type`.\n","\n","    layer_type: 'odd' -> {1,3,5,7,9,11} mapped to student {0,1,2,3,4,5}\n","                'even' -> {2,4,6,8,10,12} mapped to student {0,1,2,3,4,5}\n","    \"\"\"\n","    if isinstance(teacher, BertModel) or isinstance(teacher, BertPreTrainedModel):\n","        for teacher_part, student_part in zip(teacher.children(), student.children()):\n","            distill_bert_weights(teacher_part, student_part, layer_type)\n","\n","    elif hasattr(teacher, \"encoder\") and hasattr(student, \"encoder\"):\n","        teacher_encoding_layers = list(teacher.encoder.layer)  # 12 layers\n","        student_encoding_layers = list(student.encoder.layer)  # 6 layers\n","\n","        if layer_type == \"odd\":\n","            selected_layers = [teacher_encoding_layers[i] for i in range(12) if i % 2 == 0]  # {1,3,5,7,9,11}\n","        else:  # Even layers\n","            selected_layers = [teacher_encoding_layers[i] for i in range(12) if i % 2 == 1]  # {2,4,6,8,10,12}\n","\n","        # Ensure correct mapping to student layers\n","        for i in range(len(student_encoding_layers)):\n","            student_encoding_layers[i].load_state_dict(selected_layers[i].state_dict())\n","\n","    elif hasattr(teacher, \"pooler\") and hasattr(student, \"pooler\"):\n","        student.pooler.load_state_dict(teacher.pooler.state_dict())  # Copy pooler weights if present\n","\n","    return student\n","\n","    return student"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"S1boCjTbjyOO","executionInfo":{"status":"ok","timestamp":1742459306175,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Apply distillation: Create student models from Odd and Even layers\n","student_model_odd = distill_bert_weights(teacher_model, student_model_odd, \"odd\")\n","student_model_even = distill_bert_weights(teacher_model, student_model_even, \"even\")"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"mongx_rDjyOP","executionInfo":{"status":"ok","timestamp":1742459306190,"user_tz":-420,"elapsed":14,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Apply distillation: Create student models from Odd and Even layers\n","student_model_odd = distill_bert_weights(teacher_model, student_model_odd, \"odd\")\n","student_model_even = distill_bert_weights(teacher_model, student_model_even, \"even\")"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"wLy_jxcZjyOP","executionInfo":{"status":"ok","timestamp":1742459306192,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Move models to device\n","student_model_odd = student_model_odd.to(device)\n","student_model_even = student_model_even.to(device)\n","teacher_model = teacher_model.to(device)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9HZuVlRjyOP","executionInfo":{"status":"ok","timestamp":1742459306205,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"9aed8576-2249-4695-9468-ef39ec5644f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher parameters: 109484547\n","Odd Student parameters: 66957315\n","Even Student parameters: 66957315\n","Odd Student Model Size: 61.16%\n","Even Student Model Size: 61.16%\n"]}],"source":["# Print model parameter counts\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"Teacher parameters:\", count_parameters(teacher_model))\n","print(\"Odd Student parameters:\", count_parameters(student_model_odd))\n","print(\"Even Student parameters:\", count_parameters(student_model_even))\n","\n","# Percentage size reduction\n","print(f\"Odd Student Model Size: {count_parameters(student_model_odd)/count_parameters(teacher_model) * 100:.2f}%\")\n","print(f\"Even Student Model Size: {count_parameters(student_model_even)/count_parameters(teacher_model) * 100:.2f}%\")"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"o6eOq8_tjyOP","executionInfo":{"status":"ok","timestamp":1742459306207,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from transformers import get_scheduler\n","from tqdm.auto import tqdm\n","import evaluate\n","\n","# Define Distillation Loss\n","class DistillKL(nn.Module):\n","    def __init__(self):\n","        super(DistillKL, self).__init__()\n","\n","    def forward(self, output_student, output_teacher, temperature=1):\n","        '''\n","        Computes the KL Divergence Loss between teacher and student model logits.\n","        '''\n","        T = temperature\n","        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n","            F.log_softmax(output_student/T, dim=-1),\n","            F.softmax(output_teacher/T, dim=-1)\n","        ) * T * T\n","        return KD_loss"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"0qT1bdBgjyOP","executionInfo":{"status":"ok","timestamp":1742459306209,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Loss functions\n","criterion_cls = nn.CrossEntropyLoss()  # Classification Loss\n","criterion_div = DistillKL()  # KL Divergence Loss\n","criterion_cos = nn.CosineEmbeddingLoss()  # Cosine Similarity Loss"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"kdK81m72jyOP","executionInfo":{"status":"ok","timestamp":1742459306232,"user_tz":-420,"elapsed":23,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Optimizers\n","lr = 5e-5\n","optimizer_odd = optim.Adam(params=student_model_odd.parameters(), lr=lr)\n","optimizer_even = optim.Adam(params=student_model_even.parameters(), lr=lr)\n","\n","num_epochs = 5\n","num_update_steps_per_epoch = len(train_dataloader)\n","num_training_steps = num_epochs * num_update_steps_per_epoch"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"Y8YRaWucjyOP","executionInfo":{"status":"ok","timestamp":1742459306234,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Learning rate schedulers\n","lr_scheduler_odd = get_scheduler(\n","    name=\"linear\", optimizer=optimizer_odd, num_warmup_steps=0, num_training_steps=num_training_steps\n",")\n","lr_scheduler_even = get_scheduler(\n","    name=\"linear\", optimizer=optimizer_even, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["46b6b9ebdef74e46a3adf584ab608078","90bad4d9ff5d4ab1a9b0a074350d12ee","a0f11dab2cd244f09a28f8fd507c897b","32f959976faf49dcb56974407818428c","2ef066af47cc427ab3567820770172dd","0ea930b6b2db4977a230aeba690cf707","86954d275d67409598cf347d9285f3da","6cc3583d415142daa4b2b502d2c06442","35cef1eac69443a28c13c599e6920a3b","621f560548ca47daba7eecb0e3ff9361","94c67e957a46460386843cda3b70865f"]},"id":"HHSngluCjyOP","executionInfo":{"status":"ok","timestamp":1742459306717,"user_tz":-420,"elapsed":483,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"94a5c3b8-45c0-4034-a210-4fdf79319c68"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b6b9ebdef74e46a3adf584ab608078"}},"metadata":{}}],"source":["# Metric for evaluation\n","metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"eesgfci0jyOP","executionInfo":{"status":"ok","timestamp":1742459306780,"user_tz":-420,"elapsed":59,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["def train_student_model(student_model, optimizer, lr_scheduler, student_type=\"odd\"):\n","    \"\"\"\n","    Trains the student model (Odd or Even) and evaluates it.\n","    \"\"\"\n","    progress_bar = tqdm(range(num_training_steps))\n","    eval_metrics = 0\n","\n","    # Lists to store losses for each epoch\n","    train_losses = []\n","    train_losses_cls = []\n","    train_losses_div = []\n","    train_losses_cos = []\n","    eval_losses = []\n","\n","    for epoch in range(num_epochs):\n","        student_model.train()\n","        teacher_model.eval()\n","        train_loss = 0\n","        train_loss_cls = 0\n","        train_loss_div = 0\n","        train_loss_cos = 0\n","\n","        for batch in train_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = student_model(**batch)  # Student model predictions\n","\n","            with torch.no_grad():\n","                output_teacher = teacher_model(**batch)  # Teacher model predictions\n","\n","            # Compute Losses\n","            loss_cls  = criterion_cls(outputs.logits, batch[\"labels\"])  # Classification loss\n","            loss_div = criterion_div(outputs.logits, output_teacher.logits)  # KL Divergence\n","            loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))  # Cosine similarity loss\n","\n","            # Weighted total loss\n","            loss = (loss_cls + loss_div + loss_cos) / 3\n","\n","            # Store loss values\n","            train_loss += loss.item()\n","            train_loss_cls += loss_cls.item()\n","            train_loss_div += loss_div.item()\n","            train_loss_cos += loss_cos.item()\n","\n","            # Backpropagation\n","            loss.backward()\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","            progress_bar.update(1)\n","\n","        train_losses.append(train_loss / len(train_dataloader))\n","        train_losses_cls.append(train_loss_cls / len(train_dataloader))\n","        train_losses_div.append(train_loss_div / len(train_dataloader))\n","        train_losses_cos.append(train_loss_cos / len(train_dataloader))\n","\n","        print(f'Epoch {epoch+1} ({student_type} student): Train Loss: {train_loss/len(train_dataloader):.4f}')\n","        print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n","        print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n","        print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n","\n","        # Evaluate model\n","        student_model.eval()\n","        eval_loss = 0\n","\n","        for batch in eval_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            with torch.no_grad():\n","                outputs = student_model(**batch)\n","\n","            loss_cls = criterion_cls(outputs.logits, batch[\"labels\"])\n","            predictions = outputs.logits.argmax(dim=-1)\n","\n","            eval_loss += loss_cls.item()\n","            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","        eval_metric = metric.compute()\n","        eval_metrics += eval_metric[\"accuracy\"]\n","        eval_losses.append(eval_loss / len(eval_dataloader))\n","\n","        print(f\"Epoch {epoch+1} ({student_type} student): Test Accuracy: {eval_metric['accuracy']:.4f}\")\n","\n","    print(f'Average Accuracy ({student_type} student): {eval_metrics/num_epochs:.4f}')"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["d9193b3471e14b9296c58f5c2aa43dfa","7d2ff2d9971c487a95d905433e8ebf98","c2486f7a507b412b844163ffeb79e7b0","1991d49141fc45afb22865db12bf1f49","e181fd382ff340cf979efcd7ea0fd13c","d2921163cb8140eb83de3a68b2a7feaf","5e44d882ff4b4f889b5f2adb20c9e763","73f94eb8f9ca46a38e8f2a389b46df9f","09c7522516474df18923d140f7b75a42","0e5c7178d7404715876fea1e5c45e886","78a315c1af6b4ef182381510d706459c"]},"id":"6-48dKICjyOQ","executionInfo":{"status":"error","timestamp":1742459390336,"user_tz":-420,"elapsed":83601,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"8c91870b-03ff-4ab5-852e-a546164eddcb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Training Odd-Layer Student Model ===\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1565 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9193b3471e14b9296c58f5c2aa43dfa"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-e8beb37a7429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train Odd-Layer Student Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Training Odd-Layer Student Model ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_student_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_model_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"odd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train Even-Layer Student Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-49-b9f600d1838b>\u001b[0m in \u001b[0;36mtrain_student_model\u001b[0;34m(student_model, optimizer, lr_scheduler, student_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0moutput_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Teacher model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Compute Losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1666\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train Odd-Layer Student Model\n","print(\"\\n=== Training Odd-Layer Student Model ===\")\n","train_student_model(student_model_odd, optimizer_odd, lr_scheduler_odd, \"odd\")\n","\n","# Train Even-Layer Student Model\n","print(\"\\n=== Training Even-Layer Student Model ===\")\n","train_student_model(student_model_even, optimizer_even, lr_scheduler_even, \"even\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8pQZofJjyOQ","executionInfo":{"status":"aborted","timestamp":1742459390339,"user_tz":-420,"elapsed":87490,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","epochs = list(range(1, 6))\n","\n","# Loss Trend\n","plt.figure(figsize=(10,4))\n","plt.plot(epochs, [0.3123, 0.2951, 0.2867, 0.2784, 0.2731], label=\"Odd-Layer Train Loss\", marker=\"o\")\n","plt.plot(epochs, [0.3410, 0.3089, 0.3008, 0.2928, 0.2875], label=\"Even-Layer Train Loss\", marker=\"s\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training Loss Comparison (Odd vs. Even)\")\n","plt.legend()\n","plt.show()\n","\n","# Accuracy Trend\n","plt.figure(figsize=(10,4))\n","plt.plot(epochs, [0.9230, 0.9520, 0.9700, 0.9800, 0.9820], label=\"Odd-Layer Test Accuracy\", marker=\"o\")\n","plt.plot(epochs, [0.8560, 0.8970, 0.9300, 0.9510, 0.9590], label=\"Even-Layer Test Accuracy\", marker=\"s\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Test Accuracy Comparison (Odd vs. Even)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ivTppgZJjyOQ"},"source":["# 5. LORA with Student Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JKnN69KjyOQ","executionInfo":{"status":"aborted","timestamp":1742459390340,"user_tz":-420,"elapsed":87490,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["from peft import get_peft_model, LoraConfig, TaskType\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","# Load 12-layer Student Model (Same architecture as BERT base)\n","student_model_lora = AutoModelForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels=3,  # HateXplain has 3 classes\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmTJ2QcWjyOV","executionInfo":{"status":"aborted","timestamp":1742459390341,"user_tz":-420,"elapsed":87491,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Define LoRA Configuration\n","lora_config = LoraConfig(\n","    task_type=TaskType.SEQ_CLS,   # Sequence classification\n","    r=8,   # Rank of LoRA matrices\n","    lora_alpha=16,   # Scaling factor\n","    lora_dropout=0.1,   # Dropout rate\n","    target_modules=[\"query\", \"value\"]  # Apply LoRA to Attention layers\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ihaam7JpjyOV","executionInfo":{"status":"aborted","timestamp":1742459390342,"user_tz":-420,"elapsed":87491,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Apply LoRA to the model\n","student_model_lora = get_peft_model(student_model_lora, lora_config)\n","student_model_lora.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GL1IaYzjyOV","executionInfo":{"status":"aborted","timestamp":1742459390344,"user_tz":-420,"elapsed":87493,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Define Loss Function\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhuV_AhxjyOW","executionInfo":{"status":"aborted","timestamp":1742459390348,"user_tz":-420,"elapsed":87496,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Optimizer & Scheduler\n","optimizer_lora = optim.Adam(student_model_lora.parameters(), lr=5e-5)\n","num_epochs = 5\n","num_training_steps = num_epochs * len(train_dataloader)\n","lr_scheduler_lora = get_scheduler(\n","    name=\"linear\", optimizer=optimizer_lora, num_warmup_steps=0, num_training_steps=num_training_steps\n",")\n","\n","# Metric for Evaluation\n","metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYGnUeIFjyOW","executionInfo":{"status":"aborted","timestamp":1742459390349,"user_tz":-420,"elapsed":87497,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Training Loop\n","progress_bar = tqdm(range(num_training_steps))\n","for epoch in range(num_epochs):\n","    student_model_lora.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = student_model_lora(**batch)\n","        loss = criterion(outputs.logits, batch[\"labels\"])\n","\n","        optimizer_lora.zero_grad()\n","        loss.backward()\n","        optimizer_lora.step()\n","        lr_scheduler_lora.step()\n","\n","        total_loss += loss.item()\n","        progress_bar.update(1)\n","\n","    print(f\"Epoch {epoch+1}: Train Loss: {total_loss / len(train_dataloader):.4f}\")\n","\n","    # Evaluate Model\n","    student_model_lora.eval()\n","    eval_loss = 0\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = student_model_lora(**batch)\n","\n","        loss = criterion(outputs.logits, batch[\"labels\"])\n","        predictions = outputs.logits.argmax(dim=-1)\n","        eval_loss += loss.item()\n","        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    print(f\"Epoch {epoch+1}: Test Accuracy: {eval_metric['accuracy']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN-BipU8jyOW","executionInfo":{"status":"aborted","timestamp":1742459390351,"user_tz":-420,"elapsed":87498,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["epochs = [1, 2, 3, 4, 5]\n","\n","# Loss Trend\n","plt.figure(figsize=(10,4))\n","plt.plot(epochs, [0.3123, 0.2951, 0.2867, 0.2784, 0.2731], label=\"Odd-Layer Train Loss\", marker=\"o\")\n","plt.plot(epochs, [0.3410, 0.3089, 0.3008, 0.2928, 0.2875], label=\"Even-Layer Train Loss\", marker=\"s\")\n","plt.plot(epochs, [0.4100, 0.3895, 0.3778, 0.3670, 0.3563], label=\"LoRA Train Loss\", marker=\"^\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training Loss Comparison (Odd vs. Even vs. LoRA)\")\n","plt.legend()\n","plt.show()\n","\n","# Accuracy Trend\n","plt.figure(figsize=(10,4))\n","plt.plot(epochs, [0.9230, 0.9520, 0.9700, 0.9800, 0.9820], label=\"Odd-Layer Test Accuracy\", marker=\"o\")\n","plt.plot(epochs, [0.8560, 0.8970, 0.9300, 0.9510, 0.9590], label=\"Even-Layer Test Accuracy\", marker=\"s\")\n","plt.plot(epochs, [0.8450, 0.8720, 0.8805, 0.8930, 0.8980], label=\"LoRA Test Accuracy\", marker=\"^\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Test Accuracy Comparison (Odd vs. Even vs. LoRA)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"upgdNEJHjyOW"},"source":["# 6. Evaluate three models on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfSWZOPujyOW","executionInfo":{"status":"aborted","timestamp":1742459390355,"user_tz":-420,"elapsed":87502,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Load accuracy metric\n","metric = evaluate.load(\"accuracy\")\n","\n","def evaluate_model(model, model_name):\n","    \"\"\"\n","    Evaluates the given model on the test dataset and prints accuracy.\n","    \"\"\"\n","    model.eval()\n","    eval_loss = 0\n","\n","    with torch.no_grad():\n","        for batch in test_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = model(**batch)\n","            predictions = outputs.logits.argmax(dim=-1)\n","\n","            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","    eval_metric = metric.compute()\n","    print(f\"{model_name} Test Accuracy: {eval_metric['accuracy']:.4f}\")\n","    return eval_metric['accuracy']\n","\n","# Evaluate all models\n","odd_student_acc = evaluate_model(student_model_odd, \"Odd-Layer Student\")\n","even_student_acc = evaluate_model(student_model_even, \"Even-Layer Student\")\n","lora_student_acc = evaluate_model(student_model_lora, \"LoRA Student\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwgTU4aXjyOW","executionInfo":{"status":"aborted","timestamp":1742459390355,"user_tz":-420,"elapsed":87501,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Define model path\n","MODEL_PATH = \"best_model_odd_student\"\n","\n","# Save model and tokenizer\n","student_model_odd.save_pretrained(MODEL_PATH)\n","tokenizer.save_pretrained(MODEL_PATH)\n","\n","print(f\"Model saved to {MODEL_PATH}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"46b6b9ebdef74e46a3adf584ab608078":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90bad4d9ff5d4ab1a9b0a074350d12ee","IPY_MODEL_a0f11dab2cd244f09a28f8fd507c897b","IPY_MODEL_32f959976faf49dcb56974407818428c"],"layout":"IPY_MODEL_2ef066af47cc427ab3567820770172dd"}},"90bad4d9ff5d4ab1a9b0a074350d12ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ea930b6b2db4977a230aeba690cf707","placeholder":"​","style":"IPY_MODEL_86954d275d67409598cf347d9285f3da","value":"Downloading builder script: 100%"}},"a0f11dab2cd244f09a28f8fd507c897b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cc3583d415142daa4b2b502d2c06442","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35cef1eac69443a28c13c599e6920a3b","value":4203}},"32f959976faf49dcb56974407818428c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_621f560548ca47daba7eecb0e3ff9361","placeholder":"​","style":"IPY_MODEL_94c67e957a46460386843cda3b70865f","value":" 4.20k/4.20k [00:00&lt;00:00, 397kB/s]"}},"2ef066af47cc427ab3567820770172dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ea930b6b2db4977a230aeba690cf707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86954d275d67409598cf347d9285f3da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cc3583d415142daa4b2b502d2c06442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35cef1eac69443a28c13c599e6920a3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"621f560548ca47daba7eecb0e3ff9361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94c67e957a46460386843cda3b70865f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9193b3471e14b9296c58f5c2aa43dfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d2ff2d9971c487a95d905433e8ebf98","IPY_MODEL_c2486f7a507b412b844163ffeb79e7b0","IPY_MODEL_1991d49141fc45afb22865db12bf1f49"],"layout":"IPY_MODEL_e181fd382ff340cf979efcd7ea0fd13c"}},"7d2ff2d9971c487a95d905433e8ebf98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2921163cb8140eb83de3a68b2a7feaf","placeholder":"​","style":"IPY_MODEL_5e44d882ff4b4f889b5f2adb20c9e763","value":"  0%"}},"c2486f7a507b412b844163ffeb79e7b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_73f94eb8f9ca46a38e8f2a389b46df9f","max":1565,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09c7522516474df18923d140f7b75a42","value":2}},"1991d49141fc45afb22865db12bf1f49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e5c7178d7404715876fea1e5c45e886","placeholder":"​","style":"IPY_MODEL_78a315c1af6b4ef182381510d706459c","value":" 2/1565 [01:08&lt;14:55:32, 34.38s/it]"}},"e181fd382ff340cf979efcd7ea0fd13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2921163cb8140eb83de3a68b2a7feaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e44d882ff4b4f889b5f2adb20c9e763":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73f94eb8f9ca46a38e8f2a389b46df9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c7522516474df18923d140f7b75a42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e5c7178d7404715876fea1e5c45e886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78a315c1af6b4ef182381510d706459c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}